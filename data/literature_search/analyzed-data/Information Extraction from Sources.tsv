authors	title	abstract	publication_year	doi/url	DL	IS_ACCEPTED	publisher	paper_type	problem	approach	solution	languages	KGs	datasets	metrics	technologies	challenges/future work	source code	demo	comments
Elizaveta Zimina; Jyrki Nummenmaa; Kalervo Jarvelin; Jaakko Peltonen; Kostas Stefanidis	MuG-QA: Multilingual Grammatical Question Answering for RDF Data	We introduce [::Multilingual::] Grammatical [::Question Answering::] (MuG-[::QA::]), a system for answering questions in the English, German, Italian and French languages over [::DBpedia::]. The natural language modelling and parsing is implemented using Grammatical Framework (GF), a grammar formalism having natural support for [::multilinguality::]. The question analysis is based on forming an ab...	2018	https://doi.org/10.1109/PIC.2018.8706310	IEEE Xplore	TRUE	IEEE PIC conference	System	Rapid development of RDF and KBs, increas of non-English data	Based on forming an abstract conceptual grammar from the questions, and then using linearisation of the abstract grammar into different languages to parse the questions. Once a natural language question is parsed, the resulting abstract grammar tree is matched with the knowledge base schema and contents to formulate a SPARQL query.	The MUG-QA Grammar is formed using the grammatical framework and its resource library, the entities and classes are linked using "interlanguage-links-dataset"	English, German, Italian, French	DBpedia	QALD-7	Micro/Macro Precision, Recall, F1 Score	Grammatical Framework (GF) and The GF Resource Grammar Library	Improving "Semantic flexibility" of the system, add more languages			The grammar rule based methods requires experts and increased labor costs for creating them. Despite abstract grammar tree is language-agnostic, one still require create mappings for introducing a new language
Aleksandr Perevalov; Dennis Diefenbach; Ricardo Usbeck; Andreas Both	QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers	The ability to have the same experience for different user groups (i.e., accessibility) is one of the most important characteristics of Web-based systems. The same is true for [::Knowledge Graph::] [::Question Answering::] ([::KGQA::]) systems that provide the access to [::Semantic ::][::Web::][:: data::] via [::natural language interface::]. While following our research agenda on the [::multiling...	2022	https://doi.org/10.1109/ICSC52841.2022.00045	IEEE Xplore	TRUE	IEEE ICSC conference	Dataset	Lack of multilingual benchmarks for question answering over knowledge graphs	Use native speakers of different languages (including endangered) to translate the original questions in order to extend the dataset.	Utilize Amazon Mechanical Turk and Yandex Toloka crowdsourcing platforms, assign tasks for translation with region, phone number and skills resrtiction for the workers. In the same setting, the obtained translations are validated.	English, German, French, Russian, Ukrainian, Lithuanian, Belarusian, Bashkir, Armenian	DBpedia, Wikidata	QALD-9, QALD-9-plus	Micro/Macro Precision, Recall, F1 Score	Amazon Mechanical Turk, Yandex Toloka, Python	Add meta information, cover existing languages completely, increase number of questions and languages	https://github.com/KGQA/qald_9_plus		Not so many questions for the benchmark, needs to be extended. Not all the languages are covered completely
Aleksandr Perevalov; Axel-Cyrille Ngonga Ngomo; Andreas Both	Enhancing the Accessibility of Knowledge Graph Question Answering Systems through Multilingualization	There are around 7000 languages spoken today in the world, yet English dominates in many research communities e.g., [::Knowledge Graph::] [::Question Answering::] ([::KGQA::]). The goal of a [::KGQA::] system is to provide natural language access to a [::knowledge graph::]. While many research works aim to achieve the best possible [::QA::] quality over English benchmarks, only a small share of th...	2022	https://doi.org/10.1109/ICSC52841.2022.00048	IEEE Xplore	TRUE	IEEE ICSC conference	Review	"Digital language divide", domination of english	Increase multilingual accessibility of question answering systems over knowledge graphs	A proposal to create more multilingual benchmarks, models, and systems. Improve machine translation with named entity awareness	English, German, French, Russian, Ukrainian, Lithuanian, Belarusian, Bashkir, Armenian, Hebrew, Kannada, Chinese	DBpedia, Wikidata	QALD-9, RuBQ 2.0, CWQ, QALD-9-Plus	Micro/Macro Precision, Recall, F1 Score		Curation of high-quality benchmarks takes some time, research community needs to think on language-agnostic approaches			This is a PhD symposium paper
Jin, Qiao and Yuan, Zheng and Xiong, Guangzhi and Yu, Qianlan and Ying, Huaiyuan and Tan, Chuanqi and Chen, Mosha and Huang, Songfang and Liu, Xiaozhong and Yu, Sheng	Biomedical Question Answering: A Survey of Approaches and Challenges	Automatic Question Answering (QA) has been successfully applied in various domains such as search engines and chatbots. Biomedical QA (BQA), as an emerging QA task, enables innovative applications to effectively perceive, access, and understand complex biomedical knowledge. There have been tremendous developments of BQA in the past two decades, which we classify into five distinctive approaches: classic, information retrieval, machine reading comprehension, knowledge base, and question entailment approaches. In this survey, we introduce available datasets and representative methods of each BQA approach in detail. Despite the developments, BQA systems are still immature and rarely used in real-life settings. We identify and characterize several key challenges in BQA that might lead to this issue, and we discuss some potential future directions to explore.	2022	https://doi.org/10.1145/3490238	ACM DL	FALSE		Review					SIDER, Drugbank, Diseasome	QALD-4 Task 2, Bioinformatics						No particular focus on KGQA and multilinguality
Punjani, D. and Singh, K. and Both, A. and Koubarakis, M. and Angelidis, I. and Bereta, K. and Beris, T. and Bilidas, D. and Ioannidis, T. and Karalis, N. and Lange, C. and Pantazi, D. and Papaloukas, C. and Stamoulis, G.	Template-Based Question Answering over Linked Geospatial Data	Large amounts of geospatial data have been made available recently on the linked open data cloud and on the portals of many national cartographic agencies (e.g., OpenStreetMap data, administrative geographies of various countries, or land cover/land use data sets). These datasets use various geospatial vocabularies and can be queried using SPARQL or its OGC-standardized extension GeoSPARQL. In this paper we go beyond these approaches to offer a question answering service on top of linked geospatial data sources. Our system has been implemented as re-usable components of the Qanary question answering architecture to provide benefits for future research tasks. We give a detailed description of the architecture of the system, its underlying algorithms and its evaluation using a set of 201 natural language questions.	2018	https://doi.org/10.1145/3281354.3281362	ACM DL	FALSE	GIR 2018 Workshop	System					DBpedia							Doesn't targets on multilingual functionality
Maree, Mohammed and Rattrout, Amjad and Altawil, Muhanad and Belkhatir, Mohammed	Multi-Modality Search and Recommendation on Palestinian Cultural Heritage Based on the Holy-Land Ontology and Extrinsic Semantic Resources	The Cultural Heritage (CH) sector and its associated tourism services have been affected notably by the advancement of the Internet as well as the explosive growth of smartphones and other handheld devices. These days, visitors can access reliable CH content using Web and mobile-based interfaces. However, conventional CH systems still lack the ability to provide meaningful semantically overt results that precisely meet user information needs in this domain. In addition, they often ignore the user search context and experience, which hinders their ability to adapt their behavior to the preferences, tasks, interests, and other user functionalities. In this article, we aim to address the issue of designing a precision-oriented multilingual and multi-criteria semantic-based mobile recommender system specifically targeting Palestine's CH, a country with great historical and cultural importance. We aim to better facilitate users’ access to CH content by providing them with multiple search functionalities. In this context, a user can search for relevant information using keywords (a.k.a. tags) or sentence-like queries and the system retrieves all relevant documents based on their semantic similarity. A second option is to search using current location information to retrieve correlated historical places and events. Finally, starting from a picture of interest, a third option makes it possible to extract captions describing its content that can be used to search for additional contextually relevant information. Additionally, the proposed system aims at personalizing users’ experience through progressively delivering output that meets their information needs based on a number of parameters such as users' logging data, interests, previous searches, and location-based information. A prototype of the proposed system has been developed and tested using Android smartphones and a manually constructed ontology enriched with CH links to the Art &amp; Architecture Thesaurus (AAT) and DBpedia. By comparing our system with similar systems in this domain, findings demonstrate that it provides additional search features and functionalities to users. The proposed Holy-Land ontology is the first of its kind attempting to encode knowledge about Palestine's CH. It plays a crucial role in our proposal, serving as a pivotal entity in the combination of language-based, location-based, and visual-based retrieval strategies.	2021	https://doi.org/10.1145/3447523	ACM DL	FALSE														No open access
Diefenbach, Dennis and Migliatti, Pedro Henrique and Qawasmeh, Omar and Lully, Vincent and Singh, Kamal and Maret, Pierre	QAnswer: A Question Answering Prototype Bridging the Gap between a Considerable Part of the LOD Cloud and End-Users	We present QAnswer, a Question Answering system which queries at the same time 3 core datasets of the Semantic Web, that are relevant for end-users. These datasets are Wikidata with Lexemes, LinkedGeodata and Musicbrainz. Additionally, it is possible to query these datasets in English, German, French, Italian, Spanish, Pourtuguese, Arabic and Chinese. Moreover, QAnswer includes a fallback option to the search engine Qwant when the answer to a question cannot be found in the datasets mentioned above. These features make QAnswer as the first prototype of a Question Answering System over a considerable part of the LOD cloud.	2019	https://doi.org/10.1145/3308558.3314124	ACM DL	TRUE	WWW 2019	System	Accessibility of large amount of the LOD datasets is limited. The majority of the systems allow to access only one dataset and one language	Multilingual, KB-agnostic approach. 4-step process: question expansion, query construction, query ranking, answer decision	question expansion finds all concepts related to a particular n-gram substring, query construction combines the concepts using pre-defined algorithm for query patterns, query ranking ranks the generated queries according to a set of manually constructed features, answer decision utilizes ML binary classifier for additional filtering of queries	English, German, French, Italian, Spanish, Pourtuguese, Arabic, Chinese	Wikidata, DBpedia, MusicBrainz, DBLP, Freebase	QALD-3, QALD-4, QALD-5, QALD-6, QALD-7, LC-QuAD 1.0	Precision, Recall, F1 score, Runtime	Java, HDT	The identification of relations relies on a dictionary. Introduce non-dictionary based methods (e.g., word embeddings)		https://qanswer-frontend.univ-st-etienne.fr/	Flexible and production oriented approach. The query generation algorithm may be a bottleneck as it's not possible to foresee all possible query structures for all KGs
Souza Costa, Tarc\'{\i}sio and Gottschalk, Simon and Demidova, Elena	Event-QA: A Dataset for Event-Centric Question Answering over Knowledge Graphs	Semantic Question Answering (QA) is a crucial technology to facilitate intuitive user access to semantic information stored in knowledge graphs. Whereas most of the existing QA systems and datasets focus on entity-centric questions, very little is known about these systems' performance in the context of events. As new event-centric knowledge graphs emerge, datasets for such questions gain importance. In this paper, we present the Event-QA dataset for answering event-centric questions over knowledge graphs. Event-QA contains 1000 semantic queries and the corresponding English, German and Portuguese verbalizations for EventKG - an event-centric knowledge graph with more than 970 thousand events.	2020	https://doi.org/10.1145/3340531.3412760	ACM DL	TRUE	CIKM 2020	Dataset	Most of the existing QA systems and datasets focus on entity-centric questions, very little is known about these systems’ performance in the context of events. As new event-centric knowledge graphs emerge, datasets for such questions gain importance.	Automatically generate the semantic queries (SPARQL) for the event-centric dataset using random-walk based approach and provide reproducible framework for doing so by other researchers.	Multi-step Query Generation Pipeline: Query Type Selection, Event Extraction, Seed Relation Selection,  Query Graph Generation, Semantic Query Generation, Query Verbalization. The latter step was done manually by native speakers	English, German, Portugese	DBpedia	Event-QA	Query Complexity, Query Diversity, Verbalization Diversity	Java		https://github.com/tarcisiosouza/Event-QA		The verbalization step could be also semi-automatic. For example, 1st step is Triple2NL, 2nd step manual verification
Diefenbach, Dennis and Singh, Kamal and Maret, Pierre	WDAqua-Core1: A Question Answering Service for RDF Knowledge Bases	In the last two decades a new part of the web grew significantly, namely the Semantic Web. It contains many Knowledge Bases (KB) about different areas like music, books, publications, live science and many more. Question Answering (QA) over KBs is seen as the most promising approach to bring this data to end-users. We describe WDAqua-core1, a QA service for querying RDF knowledge-bases. It is multilingual, it supports different RDF knowledge bases and it understands both full natural language questions and keyword questions.	2018	https://doi.org/10.1145/3184558.3191541	ACM DL	TRUE	The Web Conf 2018	System	a QA solution freely available would allow to set up QA services over many new data sources and would probably also boost the publication of new RDF data-sets. 	This approach is based on the idea that many questions can be understood by ignoring the syntax and that the semantics of the words suffic	question expansion finds all concepts related to a particular n-gram substring, query construction combines the concepts using pre-defined algorithm for query patterns, query ranking ranks the generated queries according to a set of manually constructed features, answer decision utilizes ML binary classifier for additional filtering of queries	English, German, French, Italian, Spanish	DBpedia, Wikidata, MusicBrainz, DBLP	QALD-3, QALD-4, QALD-5, QALD-6, QALD-7	Precision, Recall, F1 score	Qanary				The same as row 8
Aleksandr Perevalov, Andreas Both, Dennis Diefenbach, Axel-Cyrille Ngonga Ngomo	Can Machine Translation be a Reasonable Alternative for Multilingual Question Answering Systems over Knowledge Graphs?	Providing access to information is the main and most important purpose of the Web. However, despite available easy-to-use tools (e.g., search engines, chatbots, question answering) the accessibility is typically limited by the capability of using the English language. This excludes a huge amount of people. In this work, we discuss Knowledge Graph Question Answering (KGQA) systems that aim at providing natural language access to data stored in Knowledge Graphs (KG). While several KGQA systems have been proposed, only very few have dealt with a language other than English. In this work, we follow our research agenda of enabling speakers of any language to access the knowledge stored in KGs. Because of the lack of native support for many languages, we use machine translation (MT) tools to evaluate KGQA systems regarding questions in languages that are unsupported by a KGQA system. In total, our evaluation is based on 8 different languages (including some that never were evaluated before). For the intensive evaluation, we extend the QALD-9 dataset for KGQA with Wikidata queries and high-quality translations. The extension was done in a crowdsourcing manner by native speakers of the different languages. By using multiple KGQA systems for the evaluation, we were enabled to investigate and answer the main research question: “Can MT be an alternative for multilingual KGQA systems?”. The evaluation results demonstrated that the monolingual KGQA systems can be effectively ported to the new languages with MT tools.	2022	https://doi.org/10.1145/3485447.3511940	ACM DL	TRUE	The Web Conf 2022	System	Unequal language distribution on the web and therefore unequal content accessibility. In addition, few of research initiatives are targeting the problem of multilingual access in the KGQA field.	Combine well-known KGQA systems with machine translation tools in order to see the impact of machine translation on question answering quality. Determine, whether machine translation could be an alternative to multilingual solutions.	Use original multilingual questions from the QALD-9-benchmark. Evaluate given the native support using the original questions and evaluate using machine-translated original questions with Yandex and HelsinkiNLP on QAnswer, DeepPavlov, and Platypus.	English, German, French, Russian, Ukrainian, Lithuanian, Belarusian, Bashkir, Armenian	Wikidata, DBpedia	QALD-9-Plus	Micro/Macro Precision, Recall, F1 Score	Python, Yandex Translate	Extend w.r.t. languages, number of questions, KGQA systems, MT systems, named entity aware MT solutions	https://github.com/Perevalov/mt-for-kgqa		No detailed error type analysis was given e.g., question type analysis
Vladislav Korablinov Pavel Braslavski	RuBQ: A Russian Dataset for Question Answering over Wikidata	The paper presents RuBQ, the first Russian knowledge base question answering (KBQA) dataset. The high-quality dataset consists of 1,500 Russian questions of varying complexity, their English machine translations, SPARQL queries to Wikidata, reference answers, as well as a Wikidata sample of triples containing entities with Russian labels. The dataset creation started with a large collection of question-answer pairs from online quizzes. The data underwent automatic filtering, crowd-assisted entity linking, automatic generation of SPARQL queries, and their subsequent in-house verification.  The freely available dataset will be of interest for a wide community of researchers and practitioners in the areas of Semantic Web, NLP, and IR, especially for those working on multilingual question answering. The proposed dataset generation pipeline proved to be efficient and can be employed in other data annotation projects.	2020	https://doi.org/10.1007/978-3-030-62466-8_7	Springer	TRUE	ISWC 2020	Dataset	Multilingual KBQA has received a deal of attention in the literature. However, almost all available KBQA datasets are English, Chinese datasets being an exception. Existing multilingual QALD datasets are rather small. No Russian KBQA/Semantic Parsing dataset was ever published	Collect the dataset in multiple languages including Russian via collecting question from quizes and multi-step approach including crowd-workers and machine translation.	Raw questions gathered from open Russian quiz collections. Thereafter self-implemented entity linking tool was used and results of entity linking were validated with crowd-workers using Yandex Toloka. Then, Path Generation and In-house Annotation were used to finalize the data. The original Russian questions were machine-translated with Yandex Translate to English.	Russian, English	Wikidata	RuBQ 1.0	answerable correct, answerable incorrect, unanswerable correct, unanswerable incorrect	Elasticsearch, Yandex Toloka, Yandex Translate, Python	Explore other data sources and approaches for RuBQ expansion: search query suggest APIs, a large question log, and Wikidata SPARQL query logs. Also address complex questions and questions with literals as answers, as well as the creation of a stronger baseline for RuBQ.	https://github.com/vladislavneon/RuBQ/tree/master/RuBQ_1.0		The dataset is biased towards Russian-specific entities. The machine-translated English is also doubtful. No common QA quality metrics were presented
Christina Unger André Freitas Philipp Cimiano	An Introduction to Question Answering over Linked Data		2014	https://doi.org/10.1007/978-3-319-10587-1_2	Springer	FALSE														
Ivan Rybin Vladislav Korablinov Pavel Efimov Pavel Braslavski	RuBQ 2.0: An Innovated Russian Question Answering Dataset	The paper describes the second version of RuBQ, a Russian dataset for knowledge base question answering (KBQA) over Wikidata. Whereas the first version builds on Q&A pairs harvested online, the extension is based on questions obtained through search engine query suggestion services. The questions underwent crowdsourced and in-house annotation in a quite different fashion compared to the first edition. The dataset doubled in size: RuBQ 2.0 contains 2,910 questions along with the answers and SPARQL queries. The dataset also incorporates answer-bearing paragraphs from Wikipedia for the majority of questions. The dataset is suitable for the evaluation of KBQA, machine reading comprehension (MRC), hybrid questions answering, as well as semantic parsing. We provide the analysis of the dataset and report several KBQA and MRC baseline results. The dataset is freely available under the CC-BY-4.0 license.	2021	https://doi.org/10.1007/978-3-030-77385-4_32	Springer	TRUE	ESWC 2021	Dataset	Available KBQA datasets are much scarcer than MRC; there are very few non-English datasets among them (see Section 2 for details). Russian is among top-10 languages by its L1 and L2 speakers; it has a Cyrillic script and a number of grammar features that make it quite different from e.g. English and Chinese – the languages most frequently used in NLP and Semantic Web research	Expand the dataset in multiple languages including Russian via collecting questions from query suggestion services and multi-step approach including crowd-workers and machine translation.	Raw questions gathered from the query suggestions by Google and Yandex based on previously generated query prefixes. Thereafter self-implemented entity linking tool was used and results of entity linking were validated with crowd-workers using Yandex Toloka. Then, Path Generation and In-house Annotation were used to finalize the data. The original Russian questions were machine-translated with Yandex Translate to English. The MRC part of the dataset was generated according to authors approach based on the wikipedia articles.	Russian, English	Wikidata	RuBQ 1.0, RuBQ 2.0	answerable correct, answerable incorrect, unanswerable correct, unanswerable incorrect	Elasticsearch, Yandex Toloka, Yandex Translate, Python	Disadvantage of query suggestion services as a source of questions is that we have very little control over the questions’ selection criteria, as well as a limited number of returned suggestions for each input. In addition, the services rank the returned queries by their popularity, which may result in shorter, simpler, and less varied questions. 	https://github.com/vladislavneon/RuBQ/tree/master/RuBQ_2.0		The dataset is still biased towards Russian-specific entities. The machine-translated English is also doubtful. No common QA quality metrics were presented
Philipp Cimiano Vanessa Lopez Christina Unger Elena Cabrio Axel-Cyrille Ngonga Ngomo Sebastian Walter	Multilingual Question Answering over Linked Data (QALD-3): Lab Overview	The third edition of the open challenge on Question Answering over Linked Data (QALD-3) has been conducted as a half-day lab at CLEF 2013. Differently from previous editions of the challenge, has put a strong emphasis on multilinguality, offering two tasks: one on multilingual question answering and one on ontology lexicalization. While no submissions were received for the latter, the former attracted six teams who submitted their systems’ results on the provided datasets. This paper provides an overview of QALD-3, discussing the approaches proposed by the participating systems as well as the obtained results.	2013	https://doi.org/10.1007/978-3-642-40802-1_30	Springer	TRUE	CLEF 2013	Dataset	The key challenge lies in translating the users’ information needs into a form such that they can be evaluated using standard Semantic Web query processing and inferencing techniques. To this end, systemshave to deal with a heterogeneous, distributed and very large set of highly in-terconnected data. multilinguality has become an issue of major interest for the Semantic Web community, as both the number of actors creating and publishing data in languages otherthan English, as well as the amount of users that access this data and speaknative languages other than English is growing substantially. 	To provide an up-to-date, demanding benchmark that estab-lishes a standard against which question answering systems over structured datacan be evaluated and compared.  	Manually created dataset of the QALD-JSON format with questions translated in multiple languages	English, Spanish, German, Italian, French, Dutch	DBpedia, MusicBrainz	QALD-3	Precision, Recall, F1 Score	Python	Emphasize further aspects of question answering over linked data, such as the need to deal with a variety of interconnecteddatasets as well as hybrid sources of information (structured RDF data and un-structured text), Biomedical domain	https://github.com/ag-sc/QALD/tree/master/3		Small dataset size 150 questions in total
Ricardo Usbeck Axel-Cyrille Ngonga Ngomo Bastian Haarmann Anastasia Krithara Michael Röder Giulio Napolitano	7th Open Challenge on Question Answering over Linked Data (QALD-7)	The past years have seen a growing amount of research on question answering (QA) over Semantic Web data, shaping an interaction paradigm that allows end users to profit from the expressive power of Semantic Web standards while, at the same time, hiding their complexity behind an intuitive and easy-to-use interface. On the other hand, the growing amount of data has led to a heterogeneous data landscape where QA systems struggle to keep up with the volume, variety and veracity of the underlying knowledge.	2017	https://doi.org/10.1007/978-3-319-69146-6_6	Springer	TRUE	ESWC 2017	Dataset	The key challenge lies in translating the users’ information needs into a form such that they can be evaluated using standard Semantic Web query processing and inferencing techniques. To this end, systemshave to deal with a heterogeneous, distributed and very large set of highly in-terconnected data. multilinguality has become an issue of major interest for the Semantic Web community, as both the number of actors creating and publishing data in languages otherthan English, as well as the amount of users that access this data and speaknative languages other than English is growing substantially. 	To provide an up-to-date, demanding benchmark that estab-lishes a standard against which question answering systems over structured datacan be evaluated and compared.  	Manually created dataset of the QALD-JSON format with questions translated in multiple languages	English, Spanish, German, Italian, French, Dutch, Romanian, Farsi	DBpedia	QALD-7	Micro/Macro Precision, Recall, F1 Score	Gerbil	Offer leader boards prior to the actual challenge	https://github.com/ag-sc/QALD/tree/master/7		Small dataset size 275 questions in total
Nitish Aggarwal Tamara Polajnar Paul Buitelaar	Cross-Lingual Natural Language Querying over the Web of Data		2013	https://doi.org/10.1007/978-3-642-38824-8_13	Springer	FALSE														
Christina Unger Axel-Cyrille Ngonga Ngomo Elena Cabrio	6th Open Challenge on Question Answering over Linked Data (QALD-6)	The past years have seen a growing amount of research on question answering over Semantic Web data (for an overview see [1]), shaping an interaction paradigm that allows end users to profit from the expressive power of Semantic Web standards while at the same time hiding their complexity behind an intuitive and easy-to-use interface.	2016	https://doi.org/10.1007/978-3-319-46565-4_13	Springer	TRUE	SemWebEval 2016	Dataset	Given the diversity of languages used on the web, there is an impeding need to facilitate multilingual access to semantic data. 	To provide an up-to-date, demanding benchmark that estab-lishes a standard against which question answering systems over structured datacan be evaluated and compared.  	Manually created dataset of the QALD-JSON format with questions translated in multiple languages	English, Spanish, German, Italian, French, Dutch, Romanian, Farsi	DBpedia	QALD-6	Micro/Macro Precision, Recall, F1 Score			https://github.com/ag-sc/QALD/tree/master/6		Small dataset size 350 questions in total
Sherzod Hakimov Soufian Jebbara Philipp Cimiano	AMUSE: Multilingual Semantic Parsing for Question Answering over Linked Data	The task of answering natural language questions over RDF data has received wide interest in recent years, in particular in the context of the series of QALD benchmarks. The task consists of mapping a natural language question to an executable form, e.g. SPARQL, so that answers from a given KB can be extracted. So far, most systems proposed are (i) monolingual and (ii) rely on a set of hard-coded rules to interpret questions and map them into a SPARQL query. We present the first multilingual QALD pipeline that induces a model from training data for mapping a natural language question into logical form as probabilistic inference. In particular, our approach learns to map universal syntactic dependency representations to a language-independent logical form based on DUDES (Dependency-based Underspecified Discourse Representation Structures) that are then mapped to a SPARQL query as a deterministic second step. Our model builds on factor graphs that rely on features extracted from the dependency graph and corresponding semantic representations. We rely on approximate inference techniques, Markov Chain Monte Carlo methods in particular, as well as Sample Rank to update parameters using a ranking objective. Our focus lies on developing methods that overcome the lexical gap and present a novel combination of machine translation and word embedding approaches for this purpose. As a proof of concept for our approach, we evaluate our approach on the QALD-6 datasets for English, German & Spanish.	2017	https://doi.org/10.1007/978-3-319-68288-4_20	Springer	TRUE	ISWC 2017	System	An important challenge in mapping natural language questions to SPARQL queries lies in overcoming the so called ‘lexical gap’. The lexical gap is only exacerbated when consIdering multiple languages as we face a cross-lingual gap that needs to be bridged.	Probabilistic inference to perform structured prediction in the search space of possible SPARQL queries to predict the query that has the highest probability of being the correct interpretation of the given query string. The inference process builds on approximate inference techniques, Markov Chain Monte Carlo in particular, to assign knowledge base (KB) Identifiers as well as meaning representations to every node in a dependency tree representing the syntactic dependency structure of the question. On the basis of these assigned meaning representations to every node, a full semantic representation can be computed relying on bottom-up semantic composition along the parse tree.	Approach consists of two inference layers which we call L2KB and QC. Each of these layers consists of a different factor graph optimized for different subtasks of the overall task. The first inference layer is trained using an entity linking objective that learns to link parts of the query to KB Identifiers. In particular, this inference step assigns KB Identifiers to open class words such as nouns, proper nouns, adjectives and verbs etc. The second inference layer is a query construction layer that takes the top k results from the L2KB layer and assigns semantic representations to closed class words such as question pronouns, determiners, etc. to yield a logical representation of the complete question. Final result is the SPARQL query	English, German, Spanish	DBpedia	QALD-6	Macro F1 score	Universal Dependencies, Java	Handle questions with other filtering operations	https://github.com/ag-sc/AMUSE		Relies on semantic parsing tree from which the queries are being generated, seems more or less template rule-based generation process, which is not very flexible
Ricardo UsbeckMichael RöderPeter HaaseArtem KozlovMuhammad SaleemAxel-Cyrille Ngonga Ngomo	Requirements to Modern Semantic Search Engine		2016	https://doi.org/10.1007/978-3-319-45880-9_25	Springer	FALSE														
Dennis Diefenbach José Giménez-García Andreas Both Kamal Singh Pierre Maret	QAnswer KG: Designing a Portable Question Answering System over RDF Data		2020	https://doi.org/10.1007/978-3-030-49461-2_25	Springer	TRUE	ESWC 2020	System												Same as row 8
Nitish Aggarwal	Cross Lingual Semantic Search by Improving Semantic Similarity and Relatedness Measures	Since 2001, the semantic web community has been working hard towards creating standards which will increase the accessibility of available information on the web. Yahoo research recently reported that 30% of all HTML pages contain structured data such as microdata, RDFa, or microformat. Although multilinguality of the web is a hurdle in information access, the rapid growth of the semantic web enables us to retrieve fine grained information across the language barrier. In this thesis, firstly, we focus on developing a methodology to perform cross-lingual semantic search over structured data (knowledge base), by transforming natural language queries into SPARQL. Secondly, we focus on improving the semantic similarity and relatedness measures, to overcome the semantic gap between the vocabulary in the knowledge base and the terms appearing in the query. The preliminary results are evaluated against the QALD-2 test dataset, which achieved a F1 score of 0.46, an average precision of 0.44, and an average recall of 0.48.	2012	https://doi.org/10.1007/978-3-642-35173-0_26	Springer	TRUE	ISWC 2012	System	The rapid growth of the semantic web offers a wealth of semantic knowledge for facilitating an interactive way to access the information, by providing structured metadata in a standard format such as microdata, RDFa or microformat. People desire to access the multilingual information available on the web, while querying in their native language. The poor accuracy of translation of short texts like queries, poses a certain problem	To address this issue, we present crosslingual semantic search, which aims to retrieve all the relevant information even if it is available in languages different from the query language. Using large knowledge bases as an interlingua may prove beneficial.	Interpretation of NL-queries in different languages, driven by the traversal over the large structured knowledge base, and construction of the corresponding SPARQL query. Entity search (with exact match), linguistic analysis (semantic parse tree), KG traversing for relation detection with Explicit Semantic Analysis and Word-Net based Lin	English, German	DBpedia	QALD-2	Precision, Recall, F1 score	Stanford Parser, Java	Improving the existing semantic relatedness measures			The semantic relatedness is corpus based, nowadays it could be improved with neural language models.
Mariana Damova Dana Dannélls Ramona Enache Maria Mateva Aarne Ranta	Multilingual Natural Language Interaction with Semantic Web Knowledge Bases and Linked Open Data	This chapter presents a novel approach to Semantic Web technologies with the cultural heritage domain as a use case. Semantic Web technologies offer the technological backbone to meet the requirement of integrating heterogeneous data, but they are still more adapted to be consumed by computers rather than by humans. This chapter describes a method that allows interaction with semantic knowledge bases in natural language . The proposed method enables querying a semantic repository in natural language and obtaining results from it as a coherent text. The solution involves a conversion from natural language to SPARQL on one hand and from a set of Resource Description Framework (RDF) triples to coherent natural language descriptions in multiple languages on the other. The conversions are implemented in the Grammatical Framework (GF) . The semantic knowledge infrastructure in RDF is based on OWLIM-SE and the data integration method reason-able view supplied with an ontological reference layer. The latter is connected via formal rules to a semantic representation layer and to a syntactic representation layer using GF. The resulting demonstration is a system that supports querying and text generation in 15 languages.	2014	https://doi.org/10.1007/978-3-662-43585-4_13	Springer	TRUE	Chapter of a Book 2014	System	TODO: get pdf							Grammatical Framework (GF) 				
Elena Cabrio Julien Cojan Fabien Gandon	Mind the Cultural Gap: Bridging Language-Specific DBpedia Chapters for Question Answering	In order to publish information extracted from language-specific pages of Wikipedia in a structured way, the Semantic Web community has started an effort of internationalization of DBpedia. Language-specific DBpedia chapters can contain very different information from one language to another; in particular, they provide more details on certain topics or fill information gaps. Language-specific DBpedia chapters are well connected through instance interlinking, extracted from Wikipedia. An alignment between properties is also carried out by DBpedia contributors as a mapping from the terms in Wikipedia to a common ontology, enabling the exploitation of information coming from language-specific DBpedia chapters. However, the mapping process is currently incomplete, it is time-consuming as it is performed manually, and it may lead to the introduction of redundant terms in the ontology. In this chapte, we first propose an approach to automatically extend the existing alignments, and we then present an extension of QAKiS, a system for Question Answering over Linked Data that allows to query language-specific DBpedia chapters relying on the abovementioned property alignment. In the current version of QAKiS, English, French, and German DBpedia chapters are queried using a natural language interface.	2014	https://doi.org/10.1007/978-3-662-43585-4_9	Springer	TRUE	Chapter of a Book 2014	System	Language specific DBpedia chapters can contain different information from one language to another, providing more specificity on certain topics, or filling information gaps. Being able to exploit all the amount of multilingual information would bring several advantages to systems.	To enhance users interactions with the Web of Data, query interfaces providing a flexible mapping between natural language expressions, and concepts and relations in structured knowledge bases are becoming particularly relevant. More specifically, QAKiS allows end users to submit a query to an RDF triple store in English and obtain the answer in the same language, hiding the complexity of the non intuitive formal query languages involved in the resolution process.	Relation-based matching for question interpretation, to convert the user question into a query language (e.g. SPARQL). More specifically, it makes use of relational patterns - automatically extracted from Wikipedia and collected in the WikiFramework repository  that capture different ways to express a certain relation in a given language. QAKiS is composed of four main modules: query generator, pattern matcher, NE recognizer, SPARQL package	English, French, German	DBpedia	QALD-2	Precision	Stanford Core NLP NE Recognizer	Improve the mapping extension approach by taking into account instance types to disambiguate attributes. Distributed SPARQL endpoints			It is an extension of QAKiS. The mappings has to be created for each language individually
Elena Cabrio Julien Cojan Fabien Gandon Amine Hallili	Querying Multilingual DBpedia with QAKiS	We present an extension of QAKiS, a system for open domain Question Answering over linked data, that allows to query DBpedia multilingual chapters. Such chapters can contain different information with respect to the English version, e.g. they provide more specificity on certain topics, or fill information gaps. QAKiS exploits the alignment between properties carried out by DBpedia contributors as a mapping from Wikipedia terms to a common ontology, to exploit information coming from DBpedia multilingual chapters, broadening therefore its coverage. For the demo, English, French and German DBpedia chapters are the RDF data sets to be queried using a natural language interface.	2013	https://doi.org/10.1007/978-3-642-41242-4_23	Springer	TRUE	ESWC 2013	System				English, French, German	DBpedia							The same as # 24
Nikolay Radoev Amal Zouaq Mathieu Tremblay Michel Gagnon	A Language Adaptive Method for Question Answering on French and English	The LAMA (Language Adaptive Method for question Answering) system focuses on answering natural language questions using an RDF knowledge base within a reasonable time. Originally designed to process queries written in French, the system has been redesigned to also function on the English language. Overall, we propose a set of lexico-syntactic patterns for entity and property extraction to create a semantic representation of natural language requests. This semantic representation is then used to generate SPARQL queries able to answer users’ requests. The paper also describes a method for decomposing complex queries into a series of simpler queries. The use of preprocessed data and parallelization methods helps improve individual answer times.	2018	https://doi.org/10.1007/978-3-030-00072-1_9	Springer	TRUE	SemWebEval 2018	System	Many applications rely on the SPARQL standard in order to query data based on an RDF model. The use of SPARQL does however come with a significant drawback represented by its learning curve.	Question-answering system, which is based on various multilingual (French / English) lexico-syntactic patterns that can help generate corresponding SPARQL queries. These patterns can be used in any question-answering (QA) system that wants to leverage the power of syntax and POS tagging to generate SPARQL queries.	The pre-processing phases (Syntax Parsing and Question Classification) generate additional intermediate structures (dependency tree, POS tags, question type) that are passed to the core processing module, which transforms the syntax tree in an intermediate representation. This representation is parsed to generate one or more triple patterns used in the SPARQL requests to the Knowledge Base.	French, English	DBpedia	QALD-7, LC-QuAD	F1 score	Google Translate API, word2vec, SyntaxNet, Penn Treebank, OntoNotes, Universal Dependencies	The enrichment of dependency and POS patterns, checking for logical coherence between thesystem’s output and the expected answers, audio modality			The same as "French and English Question Answering using Lexico-Syntactic Patterns". Lexico-Syntactic patterns are handcrafted. It is well-known that hand-crafted approachs can not cover all the variance of NL.
Dennis Diefenbach Kamal Singh Pierre Maret	WDAqua-core0: A Question Answering Component for the Research Community	We describe and present a new Question Answering (QA) component that can be easily used by the QA research community. It can be used to answer questions over DBpedia and Wikidata. The language support over DBpedia is restricted to English, while it can be used to answer questions in 4 different languages over Wikidata namely English, French, German and Italian. Moreover it supports both full natural language queries as well as keyword queries. We describe the interfaces to access and reuse it and the services it can be combined with. Moreover we show the evaluation results we achieved on the QALD-7 benchmark.	2017	https://doi.org/10.1007/978-3-319-69146-6_8	Springer	TRUE	SemWebEval 2017	System				English, French, German, Italian	DBpedia, Wikidata	QALD-7	Precision, Recall, F1 Score	Qanary				Same as #8
Thomas Pellissier Tanon Marcos Dias de Assunção Eddy Caron Fabian M. Suchanek	Demoing Platypus – A Multilingual Question Answering Platform for Wikidata	In this paper we present Platypus, a natural language question answering system on Wikidata. Our platform can answer complex queries in several languages, using hybrid grammatical and template based techniques. Our demo allows users either to select sample questions, or formulate their own – in any of the 3 languages that we currently support. A user can also try out our Twitter bot, which replies to any tweet that is sent to its account.	2018	https://doi.org/10.1007/978-3-319-98192-5_21	Springer	TRUE	ESWC 2018	System	Recent years have seen the rise of systems that can answer natural language questions. These systems usually rely on knowledge bases (KBs) – large, structured repositories of achinereadable facts	First, it explicitly targets Wikidata, which is one of the largest general purpose knowledge bases. Second, it supports multiple natural languages with minimal adjustments. Represent questions not directly in SPARQL, but rather in a custom logical representation. 	The representation is inspired by dependency-based compositional semantics, and adapted to work with multiple languages. The grammatical analyzer takes as input a natural language question, and translates it into a logical representation.  Then it transforms this tree to the logical representation using manually designed rules. The second Platypus analyzer is based on templates. analyzer uses these templates in order to find the logical representation of a given natural language question. For this purpose, the analyzer first finds the template that best matches the question. After this, the analyzer fills the logical representation slots. The representations are converted into SPARQL, and executed one after the other on Wikidata, until one of them yields an answer.	French, English	Wikidata	WikidataSimpleQuestions		Core NLP, Spacy, RasaNLU	The template-based analyzer one works only in English		https://qa.askplatyp.us/v0, https://askplatyp.us/	Custom logical representations can be a bottleneck.
David W. EmbleyStephen W. LiddleDeryle W. LonsdaleYuri Tijerino	Multilingual Ontologies for Cross-Language Information Extraction and Semantic Search		2011	https://doi.org/10.1007/978-3-642-24606-7_12	Springer	FALSE														
María-Dolores Olvera-LoboJuncal Gutiérrez-Artacho	Multilingual Question-Answering System in Biomedical Domain on the Web: An Evaluation		2011	https://doi.org/10.1007/978-3-642-23708-9_10	Springer	FALSE														
Wafa WaliFatma GhorbelBilel GragouriFayçal HamdiElisabeth Metais	A Multilingual Semantic Similarity-Based Approach for Question-Answering Systems		2019	https://doi.org/10.1007/978-3-030-29551-6_54	Springer	FALSE														
Nadine Steinmetz Kai-Uwe Sattler	What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs		2021	https://doi.org/10.1007/s13740-021-00128-9	Springer	FALSE														only English considered
Eleftherios Dimitrakis Konstantinos Sgontzos Yannis Tzitzikas	A survey on question answering systems over linked data and documents	Question Answering (QA) systems aim at supplying precise answers to questions, posed by users in a natural language form. They are used in a wide range of application areas, from bio-medicine to tourism. Their underlying knowledge source can be structured data (e.g. RDF graphs and SQL databases), unstructured data in the form of plain text (e.g. textual excerpts from Wikipedia), or combinations of the above. In this paper we survey the recent work that has been done in the area of stateless QA systems with emphasis on methods that have been applied in RDF and Linked Data, documents, and mixtures of these. We identify the main challenges, we categorize the existing approaches according to various aspects, we review 21 recent systems, and 23 evaluation and training datasets that are most commonly used in the literature categorized according to the type of the domain, the underlying knowledge source, the provided tasks, and the associated evaluation metrics.	2020	https://doi.org/10.1007/s10844-019-00584-7	Springer	TRUE	Journal of Intelligent Information Systems 2020	Review	Apart from covering more recent systems, up to 2018, this survey contains a detailed list of available training/evaluation datasets for QA, an aspect that is not covered by the past surveys.	We believe that the list of evaluation datasets provided in this survey can be a valuable guide to researchers for choosing the datasets that best suit their needs and hypotheses.  Another distinctive characteristic of the current survey is that it discusses how different types of QAs and information sources can be combined to a unified pipeline, in order to help researchers to find combinatorial ways that can be more effective.	A survey on Question Answering that covers text based, data based and hybrid approaches. Also the datasets are covered		DBpedia, Freebase	WebQuestions, SimpleQuestions, QALD-1, QALD-2, QALD-3, LC-QuAD, QALD-4, QALD-5, QALD-6, QALD-7	Accuracy, Precision, Recall, F-measure, Average Precision, Mean Average Precision, Mean Reciprocal Rank					Only small paragraph about multilinguality. No protocol of survey described
Dennis DiefenbachVanessa LopezKamal SinghPierre Maret	Core techniques of question answering systems over knowledge bases: a survey		2018	https://doi.org/10.1007/s10115-017-1100-y	Springer	FALSE														
Shiqi LiangKurt StockingerTarcisio Mendes de FariasMaria AnisimovaManuel Gil	Querying knowledge graphs in natural language		2021	https://doi.org/10.1186/s40537-020-00383-w	Springer	FALSE														
José Wellington Franco da SilvaAmanda Drielly Pires VenceslauJuliano Efson SalesJosé Gilvan Rodrigues MaiaVládia Célia Monteiro PinheiroVânia Maria Ponte Vidal	A short survey on end-to-end simple question answering systems		2020	https://doi.org/10.1007/s10462-020-09826-5	Springer	FALSE														
Aleksandr Perevalov and Dennis Diefenbach and Ricardo Usbeck and Andreas Both	QALD-9-plus: {A} Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers		2022	https://doi.org/10.1109/ICSC52841.2022.00045	DBLP	TRUE	ICSC 2022	Dataset												The same as #3
Aleksandr Perevalov and Axel{-}Cyrille Ngonga Ngomo and Andreas Both	Enhancing the Accessibility of Knowledge Graph Question Answering Systems through Multilingualization		2022	https://doi.org/10.1109/ICSC52841.2022.00048	DBLP	TRUE	ICSC 2022	Review												The same as #4
Yucheng Zhou and Xiubo Geng and Tao Shen and Wenqiang Zhang and Daxin Jiang	Improving Zero-Shot Cross-lingual Transfer for Multilingual Question Answering over Knowledge Graph	Multilingual question answering over knowledge graph (KGQA) aims to derive answers from a knowledge graph (KG) for questions in multiple languages. To be widely applicable, we focus on its zero-shot transfer setting. That is, we can only access training data in a high-resource language, while need to answer multilingual questions without any labeled data in target languages. A straightforward approach is resorting to pre-trained multilingual models (e.g., mBERT) for cross-lingual transfer, but there is a still significant gap of KGQA performance between source and target languages. In this paper, we exploit unsupervised bilingual lexicon induction (BLI) to map training questions in source language into those in target language as augmented training data, which circumvents language inconsistency between training and inference. Furthermore, we propose an adversarial learning strategy to alleviate syntax-disorder of the augmented data, making the model incline to both language- and syntax-independence. Consequently, our model narrows the gap in zero-shot cross-lingual transfer. Experiments on two multilingual KGQA datasets with 11 zero-resource languages verify its effectiveness.	2021	https://doi.org/10.18653/v1/2021.naacl-main.465	DBLP	TRUE	NAACL 2021	System	Recently, a rising demand of KGQA systems is to answer the multilingual questions, motivating us to focus on multilingual KGQA. However, building a large-scale KG, as well as annotating QA data, is costly for each new language, not to mention many minority languages with a few native annotators. It is witnessed that there is a considerable KGQA performance gap between source and target languages, which is consistent with the empirical results on a wide range of other tasks by prior works.	Pre-train a Transformer encoder  on largescale non-parallel multilingual corpora in a selfsupervised manner. Then given an NLP task, a general paradigm for zero-shot cross-lingual transfer is to fine-tune a pre-trained multilingual encoder on the data in a data-rich (source) language. And the fine-tuned model is generalizable enough to perform inference in other low-resource (target) languages with surprising quality of prediction. This paradigm can be adapted to KGQA to build symbolic logical forms for KG query. Adapt the translation approaches in our zero-resource scenario, we naturally propose to replace the full-supervised machine translator with unsupervised bilingual lexicon induction (BLI) for word-level translation.	a BLI-based augmentation for multilingual training data, followed by our adaptation of the monolingual base framework to the augmented data. Finally, we propose an adversarial learning strategy coupled with BLI-based augmentation for robust cross-lingual transfer.	English, Farsi, German, Romainan, Italian, Russian, French, Dutch, Spanish, Hindi, Portugese	DBpedia	LC-QuAD, QALD-9	ICA, F1 score	Google Translate				LC-QuAD machine translated to multiple languages
Wafa Wali and Fatma Ghorbel and Bilel Gargouri and Fay{\c{c}}al Hamdi and Elisabeth M{\'{e}}tais	A Multilingual Semantic Similarity-Based Approach for Question-Answering Systems		2019	https://doi.org/10.1007/978-3-030-29551-6_54	DBLP	FALSE														
Thomas Pellissier Tanon and Marcos Dias de Assun{\c{c}}{\~{a}}o and Eddy Caron and Fabian M. Suchanek	Demoing Platypus - {A} Multilingual Question Answering Platform for Wikidata		2018	https://doi.org/10.1007/978-3-319-98192-5_21	DBLP	TRUE		System												The same as #28
Sherzod Hakimov and Soufian Jebbara and Philipp Cimiano	{AMUSE:} Multilingual Semantic Parsing for Question Answering over Linked Data		2018	https://doi.org/10.1007/978-3-319-68288-4_20	DBLP	TRUE	 ISWC 2017	System												The same as #19
Amir Pouran Ben Veyseh	Cross-Lingual Question Answering Using Common Semantic Space	With the advent of Big Data concept, a lot of attention has been paid to structuring and giving semantic to this data. Knowledge bases like DBPedia play an important role to achieve this goal. Question answering systems are common approach to address expressivity and usability of information extraction from knowledge bases. Recent researches focused only on monolingual QA systems while cross-lingual setting has still so many barriers. In this paper we introduce a new cross-lingual approach using a unified semantic space among languages. After keyword extraction, entity linking and answer type detection, we use cross lingual semantic similarity to extract the answer from knowledge base via relation selection and type matching. We have evaluated our approach on Persian and Spanish which are typologically different languages. Our experiments are on DBPedia. The results are promising for both languages.	2016	https://doi.org/10.18653/v1/w16-1403	DBLP	TRUE	TextGraphs-10 2016	System	While existing approaches focused only on English language, there are so many difficulties to cope with in cross lingual setting. On the one hand, lack of tools and resources, and on the other hand, vocabulary gap between source and target languages, frustrate any effort to adapt the existing approaches for languages other than English.	Any given question passes through four stages in a pipeline including 1. Keyword Extraction, 2. Keyword Type Detection, 3. Entity Linking & Ontology Type Extraction, and finally 4. Answer Extraction. 	A MaxEnt Markov Model is used in order to extract these keywords through sequence labelling. In the second stage each keyword is classified as 1. Type Detector, 2. Grounded Entity or 3. Neutral. To do that we have utilized an SVM classifier with RBF kernel. To do entity linking, results of queries over three different collections are merged with different weights and the first result is selected. All entities in 2-hop vicinity of the found entities in KB whose types are different from extracted ontology types are pruned. If there are entities of desired types with different path labels to the found entities, the cross lingual semantic similarity model is used to select the most similar relation with the keywords of tagged as Neutral. We have used unified vectores constructed according to BabelNet synsets	English, Persian, Spanish	DBpedia	QALD-5	Precision, Recall, F1 score	Google Translate	More investigation on relation extraction is needed. Extending our method for other KBs that don’t have versions in other languages like Freebase and also other datasets like WebQuestions (Berant et al., 2013) is another room for future work. Adapting and evaluating our method in cross-dialect setting has been left for future work.			Not clear whether there are language independent models are used in some steps (e.g., SVM)
Elena Cabrio and Philipp Cimiano and Vanessa L{\'{o}}pez and Axel{-}Cyrille Ngonga Ngomo and Christina Unger and Sebastian Walter	{QALD-3:} Multilingual Question Answering over Linked Data		2013		DBLP	TRUE		Dataset												The same as #15
Julien Cojan and Elena Cabrio and Fabien Gandon	Filling the gaps among DBpedia multilingual chapters for question answering		2013	https://doi.org/10.1145/2464464.2464500	DBLP	TRUE		System												The same as #24
{\'{O}}scar Ferr{\'{a}}ndez and Christian Spurk and Milen Kouylekov and Iustin Dornescu and Sergio Ferr{\'{a}}ndez and Matteo Negri and Rub{\'{e}}n Izquierdo and David Tom{\'{a}}s and Constantin Orasan and Guenter Neumann and Bernardo Magnini and Jos{\'{e}} Luis Vicedo Gonz{\'{a}}lez	The {QALL-ME} Framework: {A} specifiable-domain multilingual Question Answering architecture	This paper presents the QALL-ME Framework, a reusable architecture for building multi- and cross-lingual Question Answering (QA) systems working on structured data modelled by an ontology. It is released as free open source software with a set of demo components and extensive documentation, which makes it easy to use and adapt. The main characteristics of the QALL-ME Framework are: (i) its domain portability, achieved by an ontology modelling the target domain; (ii) the context awareness regarding space and time of the question; (iii) the use of textual entailment engines as the core of the question interpretation; and (iv) an architecture based on Service Oriented Architecture (SOA), which is realized using interchangeable web services for the framework components. Furthermore, we present a running example to clarify how the framework processes questions as well as a case study that shows a QA application built as an instantiation of the QALL-ME Framework for cinema/movie events in the tourism domain.	2011	https://doi.org/10.1016/j.websem.2011.01.002	DBLP	TRUE	Journal of Web Semantics	System	The exponential growth of digital information requires processes capable of searching, filtering, retrieving and classifying such information. In this context, Question Answering (QA) aims to provide relevant information to end-users as correct answers to an arbitrary question through a search in both unstructured and structured collections of data	A reusable architecture skeleton for building multilingual QA systems that answer questions with the help of structured answer data sources from freely specifiable domains. Its components can be easily expanded and replaced with other implementations, domain portability can be achieved by means of an ontology specifying the target domain. Moreover, in order to enhance interoperability and ease of use, the framework seeks to be as far as possible compliant with current standards.	The QALL-ME Framework workflow is managed by the QA Planner, which is in charge of orchestrating the web service components and thus passing the input question through the whole QA system until an answer is found: - Language Identification, - Entity Annotation, - Term Annotation, - Temporal Expression Annotation, - Query Generation	German, Spanish, English, Italian			Accuracy, RTE	Java	 acquisition of minimal question patterns, more efforts have to be undertaken in Interactive QA	http://qallme.sourceforge.net/docs/sec_Tutorials.html#sec_GettingReadyForTheFramework		The components are dictionary based, code is outdated, demo does not work
Евсеев Д. А. Архипов М. Ю	ГЕНЕРАЦИЯ SPARQL-ЗАПРОСОВ ДЛЯ ОТВЕТА НА СЛОЖНЫЕ ВОПРОСЫ С ПОМОЩЬЮ BERT И BILSTM	В данной работе описывается вопросно-ответная система для ответа на сложные вопросы по базе знаний Wikidata. В отличие от простых вопросов, для ответа на которые требуется найти один факт в базе знаний, сложные вопросы требуют извлечения более 1 триплета, а также логические или сравнительные рассуждения. Предложенная система переводит вопрос на естественном языке в запрос на языке SPARQL, выполнение которого дает ответ. В состав системы входят модели, которые определяют шаблон SPARQL-запроса, соответствующего вопросу, и затем заполняют пустые места в шаблоне сущностями, отношениями и численными значениями. Для извлечения сущностей мы использовали модель маркировки последовательностей на основе BERT. Ранжирование возможных отношений для вопроса происходит в два этапа с помощью моделей на основе BiLSTM и BERT. Предложенные модели — первое решение для датасета LC-QUAD2.0. Система способна отвечать на во	2020	https://www.dialog-21.ru/media/5088/evseevdaplusarkhipov-myu-048.pdf	Cyberleninka	TRUE	Dialog 21 2020	System	Create a system capable of answering complex questions with logical or comparative reasoning.	Decompose the task of KBQA into query template prediction, entity detection, entity linking, relation ranking, path ranking, constraint extraction (if the question has constraints) and generation of query from extracted entities, relations and constraints.	KBQA pipeline based on deep learning neural networks. . Classification of questions by query template type using BERT (CLS token), Entity Detection with BERT-based sequence labeling, Entity Linking is implemented using fuzzy matching of the string extracted at Entity Detection step with inverted index, relation ranking implemented with extracting relation candidates from the linked entities, the question's token embeddings are passed to the 2-layer Bi-LSTM to obtain hidden states which are taken for the dot product of relation embeddings (of their title) and passed to softmax layer (the model is trained to maximize product of token embedding and right relation embedding), BERT is used for path ranking of relation candidates, regular expressions are used to extract modifiers	English, Russian	Wikidata	LC-QuAD 2.0	Precision, Recall, F1 Score	DeepPavlov, Python		http://docs.deeppavlov.ai/en/master/features/models/kbqa.html		The used models and therefore the whole system is quite resource hungry, for proper functionality on CPU machine it requires around 32 GB of RAM.
Постаногов Игорь Сергеевич; Турова Ирина Алексеевна	Платформа комплексирования и тестирования средств трансформации естественно-языковых <b>запросов</b> в <b>SPARQL</b>-<b>запросы</b>	Статья посвящена <b>вопросу</b> поддержки процесса создания средства трансформации естественно-языковых (ЕЯ) <b>запросов</b> в <b>SPARQL</b>-<b>запросы</b> (далее средство трансформации).	2019	https://cyberleninka.ru/article/n/platforma-kompleksirovaniya-i-testirovaniya-sredstv-transformatsii-estestvenno-yazykovyh-zaprosov-v-sparql-zaprosy	Cyberleninka	FALSE		System												
Zhou, Yucheng  and Geng, Xiubo  and Shen, Tao  and Zhang, Wenqiang  and Jiang, Daxin	Improving Zero-Shot Cross-lingual Transfer for Multilingual Question Answering over Knowledge Graph	Multilingual question answering over knowledge graph (KGQA) aims to derive answers from a knowledge graph (KG) for questions in multiple languages. To be widely applicable, we focus on its zero-shot transfer setting. That is, we can only access training data in a high-resource language, while need to answer multilingual questions without any labeled data in target languages. A straightforward approach is resorting to pre-trained multilingual models (e.g., mBERT) for cross-lingual transfer, but there is a still significant gap of KGQA performance between source and target languages. In this paper, we exploit unsupervised bilingual lexicon induction (BLI) to map training questions in source language into those in target language as augmented training data, which circumvents language inconsistency between training and inference. Furthermore, we propose an adversarial learning strategy to alleviate syntax-disorder of the augmented data, making the model incline to both language- and syntax-independence. Consequently, our model narrows the gap in zero-shot cross-lingual transfer. Experiments on two multilingual KGQA datasets with 11 zero-resource languages verify its effectiveness.	2021	https://doi.org/10.18653/v1/2021.naacl-main.465	ACL Anthology	TRUE		System												The same as #39
Khakhmovich, Aleksandr  and Pavlova, Svetlana  and Kirillova, Kira  and Arefyev, Nikolay  and Savilova, Ekaterina	Cross-lingual Named Entity List Search via Transliteration	Out-of-vocabulary words are still a challenge in cross-lingual Natural Language Processing tasks, for which transliteration from source to target language or script is one of the solutions. In this study, we collect a personal name dataset in 445 Wikidata languages (37 scripts), train Transformer-based multilingual transliteration models on 6 high- and 4 less-resourced languages, compare them with bilingual models from (Merhav and Ash, 2018) and determine that multilingual models perform better for less-resourced languages. We discover that intrinsic evaluation, i.e comparison to a single gold standard, might not be appropriate in the task of transliteration due to its high variability. For this reason, we propose using extrinsic evaluation of transliteration via the cross-lingual named entity list search task (e.g. personal name search in contacts list). Our code and datasets are publicly available online.	2020	https://aclanthology.org/2020.lrec-1.524	ACL Anthology	FALSE														
Reddy, Siva  and T{\"a}ckstr{\"o}m, Oscar  and Petrov, Slav  and Steedman, Mark  and Lapata, Mirella	Universal Semantic Parsing	Universal Dependencies (UD) offer a uniform cross-lingual syntactic representation, with the aim of advancing multilingual applications. Recent work shows that semantic parsing can be accomplished by transforming syntactic dependencies to logical forms. However, this work is limited to English, and cannot process dependency graphs, which allow handling complex phenomena such as control. In this work, we introduce UDepLambda, a semantic interface for UD, which maps natural language to logical forms in an almost language-independent fashion and can process dependency graphs. We perform experiments on question answering against Freebase and provide German and Spanish translations of the WebQuestions and GraphQuestions datasets to facilitate multilingual evaluation. Results show that UDepLambda outperforms strong baselines across languages and datasets. For English, it achieves a 4.9 F1 point improvement over the state-of-the-art on GraphQuestions.	2017	https://doi.org/10.18653/v1/D17-1009	ACL Anthology	TRUE	EMNLP 2017	System	Recent work shows that semantic parsing can be accomplished by transforming syntactic dependencies to logical forms. However, this work is limited to English, and cannot process dependency graphs, which allow handling complex phenomena such as control.	Convert natural language to logical forms which in turn are converted to machine interpretable formal meaning representations for retrieving answers to questions from Freebase	A semantic interface for Universal Dependencies that maps natural language to logical forms, representing underlying predicate-argument structures, in an almost language-independent manner.	English, German, Spanish	Freebase	WebQuestions, GraphQuestions	F1 Score	Universal Dependencies, Java	Explore how this framework can benefit applications such as summarization and machine reading 	https://github.com/sivareddyg/udeplambda		Not sure how to extend it to the other languages technically. Provides machine translated datasets
Zhang, Lei  and F{\"a}rber, Michael  and Rettinger, Achim	x{L}i{D}-Lexica: Cross-lingual Linked Data Lexica	In this paper, we introduce our cross-lingual linked data lexica, called xLiD-Lexica, which are constructed by exploiting the multilingual Wikipedia and linked data resources from Linked Open Data (LOD). We provide the cross-lingual groundings of linked data resources from LOD as RDF data, which can be easily integrated into the LOD data sources. In addition, we build a SPARQL endpoint over our xLiD-Lexica to allow users to easily access them using SPARQL query language. Multilingual and cross-lingual information access can be facilitated by the availability of such lexica, e.g., allowing for an easy mapping of natural language expressions in different languages to linked data resources from LOD. Many tasks in natural language processing, such as natural language generation, cross-lingual entity linking, text annotation and question answering, can benefit from our xLiD-Lexica.	2014	http://www.lrec-conf.org/proceedings/lrec2014/pdf/248_Paper.pdf	ACL Anthology	FALSE														
Amir Pouran Ben Veyseh	Cross-lingual question answering using common semantic space (UTQA)		2016			TRUE		System												The same as #43
	Natural language queries over heterogeneous linked data graphs: A distributional-compositional semantics approach					FALSE														
Konrad Höffner Sebastian Walter Edgard Marx Ricardo Usbeck Jens Lehmann Axel-Cyrille Ngonga Ngomo	Survey on Challenges of Question Answering in the Semantic Web	Semantic Question Answering (SQA) removes two major access requirements to the Semantic Web: the mastery of a formal query language like SPARQL and knowledge of a specific vocabulary. Because of the complexity of natural language, SQA presents difficult challenges and many research opportunities. Instead of a shared effort, however, many essential components are redeveloped, which is an inefficient use of researcher’s time and resources. This survey analyzes 62 different SQA systems, which are systematically and manually selected using predefined inclusion and exclusion criteria, leading to 72 selected publications out of 1960 candidates. We identify common challenges, structure solutions, and provide recommendations for future systems. This work is based on publications from the end of 2010 to July 2015 and is also compared to older but similar surveys.	2016	http://www.semantic-web-journal.net/system/files/swj1375.pdf	Related Work	TRUE	Semantic Web Journal 2016	Review	While the massive research effort has led to major advances, as shown by the yearly Question Answering over Linked Data (QALD) evaluation campaign, it suffers from several problems: Instead of a shared effort, many essential components are redeveloped. While shared practices emerge over time, they are not systematically collected. Furthermore, most systems focus on a specific aspect while the others are quickly implemented, which leads to low benchmark scores and thus undervalues the contribution	Alleviate these problems by systematically collecting and structuring methods of dealing with common challenges faced by these approaches	Complement existing work with 72 publications about 62 systems developed from 2010 to 2015. Second, we identify challenges faced by those approaches and collect solutions for them from the 72 publications. Finally, we draw conclusions and make recommendations on how to develop future SQA systems.		Wikidata, DBpedia, Freebase, YAGO	QALD-1, QALD-2, QALD-3, QALD-4	Precision, Recall	Google Scholar	Future research should be directed at more modularization, automatic reuse, self-wiring and encapsulated modules with their own benchmarks and evaluations. Benchmarking will move to single algorithmic modules instead of benchmarking a system as a whole. There is a movement towards multilingual, multi-knowledgesource SQA systems that are capable of understanding noisy, human natural language input.			Only one paragraph targeting multilingualism
Ruixiang Cui, Rahul Aralikatte, Heather Lent, Daniel Hershcovich	Multilingual Compositional Wikidata Questions	Semantic parsing allows humans to leverage vast knowledge resources through natural interaction. However, parsers are mostly designed for and evaluated on English resources, such as CFQ (Keysers et al., 2020), the current standard benchmark based on English data generated from grammar rules and oriented towards Freebase, an outdated knowledge base. We propose a method for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and introduce such a dataset called Compositional Wikidata Questions (CWQ). We utilize this data to train and evaluate semantic parsers for Hebrew, Kannada, Chinese and English, to better understand the current strengths and weaknesses of multilingual semantic parsing. Experiments on zero-shot cross-lingual transfer demonstrate that models fail to generate valid queries even with pretrained multilingual encoders. Our methodology, dataset and results will facilitate future research on semantic parsing in more realistic and diverse settings than has been possible with existing resources.	2021	https://arxiv.org/abs/2108.03509	Related Work	TRUE	Arxiv	Dataset	Semantic parsing allows humans to leverage vast knowledge resources through natural interaction. However, parsers are mostly designed for and evaluated on English resources, such as CFQ, the current standard benchmark based on English data generated from grammar rules and oriented towards Freebase, an outdated knowledge base. The current barrier to extending multilingual KGQA approaches beyond English is a lack of parallel dataset from multilingual databases as well as supervision for semantic parsing.	Propose a method for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and introduce such a dataset called Compositional Wikidata Questions (CWQ), while utilize this data to train and evaluate semantic parsers for Hebrew, Kannada, Chinese and English, to better understand the current strengths and weaknesses of multilingual semantic parsing. 	Migration from Freebase to Wikidata using: property mapping, entity substitution. Machine translation of English questions using heuristics	Hebrew, Kannada, Chinese	Wikidata, Freebase	CFQ	Accuracy, BLEU	Google Translate	Observe that seq2seq semantic parsers struggle to generalize compositionally on CWQ and that zero-shot cross-lingual transfer fails to generate valid queries with pretrained multilingual encoders. The experiments demonstrate that multilingual KBQA remains a challenge. 	https://github.com/coastalcph/seq2sparql		Machine translated questions
Dennis Diefenbach, Vanessa Lopez, Kamal Singh, Pierre Maret 	Core techniques of question answering systems over knowledge bases: a survey	The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difficult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. The aim of this survey is to give an overview of the techniques used in current QA systems over KBs. We present the techniques used by the QA systems which were evaluated on a popular series of benchmarks: Question Answering over Linked Data. Techniques that solve the same task are first grouped together and then described. The advantages and disadvantages are discussed for each technique. This allows a direct comparison of similar techniques. Additionally, we point to techniques that are used over WebQuestions and SimpleQuestions, which are two other popular benchmarks for QA systems.	2018	https://doi.org/10.1007/s10115-017-1100-y	Related Work	TRUE	Knowledge and Information Systems	Review	The Semantic Web contains an enormous amount of information in the form of knowledge bases (KB). To make this information available, many question answering (QA) systems over KBs were created in the last years. Building a QA system over KBs is difficult because there are many different challenges to be solved. In order to address these challenges, QA systems generally combine techniques from natural language processing, information retrieval, machine learning and Semantic Web. 	Differently from other surveys in the field of QA over KBs, we focus on the techniques behind existing QA systems. We identified five tasks in the QA process and describe how QA systems solve them. This way each QA system participating in QALD is decomposed and compared. The tasks are question analysis, phrase mapping, disambiguation, query construction and querying distributed knowledge. Our main aim is to describe, classify and compare all techniques used by QA systems participating in QALD. This provides a good overview on how QA systems over KBs work.	Сonsider the QA systems that either directly participated in the QALD challenges or that were evaluated afterwards reusing the same evaluation set-up. To identify the latter systems, we searched in Google Scholar for all publications mentioning or citing the publications of the QALD challenges. From among these, we took the publications referring to QA system with the exclusion of controlled natural language systems		Wikidata, DBpedia, Freebase, YAGO	WebQuestions, QALD-1, QALD-2, QALD-3, QALD-4, QALD-5, QALD-6, SimpleQuestions	Precision, Recall, F1 score		The multilinguality applies if the vocabulary in the user query and the KB vocabulary are expressed (lexicalized) in different languages. 			Only some sentences are mentioning the multilinguality as an issue
José Wellington Franco da Silva, Amanda Drielly Pires Venceslau, Juliano Efson Sales, José Gilvan Rodrigues Maia, Vládia Célia Monteiro Pinheiro, Vânia Maria Ponte Vidal 	A short survey on end-to-end simple question answering systems	Searching for a specific and meaningful piece of information in the humongous textual data volumes found on the internet and knowledge repositories is a very challenging task. This problem is usually constrained to answering simple, factoid questions by resorting to a question answering (QA) system built on top of complex approaches such as heuristics, information retrieval, and machine learning. More precisely, deep learning methods became into sharp focus of this research field because such purposes can realize the benefits of the vast amounts of data to boost the practical results of QA systems. In this paper, we present a systematic survey on deep learning-based QA systems concerning factoid questions, with particular focus on how each existing system addresses their critical features in terms of learning end-to-end models. We also detail the evaluation process carried out on these systems and discuss how each approach differs from the others in terms of the challenges tackled and the strategies employed. Finally, we present the most prominent research problems still open in the field.	2020	https://doi.org/10.1007/s10462-020-09826-5	Related Work	TRUE	Artificial Intelligence Review	Review	Traditionally, the process of answering a question can be divided into five steps corresponding to question analysis, phrase mapping, disambiguation, query construction and querying distributed knowledge. However, given the improvements of deep neural network models and higher availability of training data, end-to-end architectures became state of the art	A systematic survey on deep learning-based QA systems concerning factoid questions, with particular focus on how each existing system addresses their critical features in terms of learning end-to-end models. Also detail the evaluation process carried out on these systems and discuss how each approach differs from the others in terms of the challenges tackled and the strategies employed	The works presented hereby were selected by adopting the following criteria, which are explained below: 1. An initial search for works in QA which adopt deep learning techniques. 2. Our scope has been reduced to those adopting the SimpleQuestions factoid question base as their Golden Standard. 3. Finally, only those works providing clues for answering the research questions aforementioned were considered in this survey. Define search query + research databases, filter by publication year		DBpedia, Freebase, MusicBrainz	WebQuestions, QALD, SimpleQuestions	Precision		the critical challenge faced by multilingual QA systems thus consists of performing mediation on the need for user information in their local language and semantic data expressed using traits of the diverse cultures that permeate the writing of these documents.			Only one paragraph targeting multilingualism
Christina Antoniou and Nick Bassiliades 	A survey on semantic question answering systems	Recently, many question answering systems that derive answers from linked data repositories have been developed. The purpose of this survey is to identify the common features and approaches of the semantic question answering (SQA) systems, although many different and prototype systems have been designed. The SQA systems use a formal query language like SPARQL and knowledge of a specific vocabulary. This paper analyses different frameworks, architectures, or systems that perform SQA and classifies SQA systems based on different criteria.	2022	https://doi.org/10.1017/S0269888921000138	Related Work	TRUE	Knowledge Engineering Review	Review	No categories of SQA systems have been identified (no typology/taxonomy). To date, there are no surveys for the categorization of SQA systems.	This article distinguishes categories of SQA systems based on criteria in order to lay the groundwork for a collection of common practices as no categories of SQA systems have been identified. This categorization can also serve as an archive of frameworks and systems where each system is classified according to the techniques that it uses for various criteria, such as types of questions, types of analysis done on questions, types of representations used for questions, and their matching functions. This can help developers, or anyone interested to find out directly the technique or steps used by each system, or to benchmark her own system against existing ones.	The classification we created is based on types of domains, types of data sources, types of questions, types of analysis done on questions, types of representations used for questions and types of representations used for questions and their matching functions, characteristics of the KB, types of techniques used for retrieving answers, user interaction, and answers		DBpedia, Freebase YAGO, MusicBrainz, Music Ontology, SIDER,  Diseasome, Drugbank, Medicine Ontology, LinkedGeoDat	QALD-1, QALD-2, QALD-3, QALD-4, QALD-5	Precision					Only one paragraph targeting multilingualism
Chen Zhanga, Yuxuan Laic, Yansong Feng, Dongyan Zhao	A review of deep learning in question answering over knowledge bases	Question answering over knowledge bases (KBQA) is a challenging task in natural language processing. It requires machines to answer natural language questions based on large-scale knowledge bases. Recent years have witnessed remarkable success of neural network models on many natural language processing tasks, including KBQA. In this paper, we first review the recent advances of deep learning methods on solving simple questions in two streams, the information extraction style and semantic parsing style. We then introduce how to extend the neural architectures to answer more complex questions with iteration and decomposition techniques, and summarize current research challenges.	2021	https://doi.org/10.1016/j.aiopen.2021.12.001	Related Work	TRUE	AI Open	Review	Recent advances in deepl learning are entering KBQA field in order to improve the systems	review the recent deep learning based KBQA efforts for simple questions in two main streams, the information extraction style and the semantic parsing style. Then, we switch to the efforts that extend the neural architectures to answer more complex questions that require deep reasoning over multiple KB triples. Next, we review several typical benchmarks for evaluating KBQA systems. Finally, we summarize current challenges in KBQA and discuss promising directions.	A review on DL based methods for KBQA and the corresponding datasets		Freebase, DBpedia, Wikidata	WebQuestions, WebQuestionsSP, Free917, SimpleQuestions, WikiMovies, ComplexQuestions, ComplexWebQuestions, QALD, LC-QuAD 1.0, LC-QuAD 2.0	F1 Score		Сompositional generalizability, Gap between natural language and knowledge base, lack of training data, Limited coverage of KBs, lack of data in languages other than English			No publication selection protocol is published, only one line about multilinguality
Arnaldo Pereira, Alina Trifan, Rui Pedro Lopes, José Luís Oliveira	Systematic review of question answering over knowledge bases	Over the years, a growing number of semantic data repositories have been made available on the web. However, this has created new challenges in exploiting these resources efficiently. Querying services require knowledge beyond the typical user’s expertise, which is a critical issue in adopting semantic information solutions. Several proposals to overcome this difficulty have suggested using question answering (QA) systems to provide user-friendly interfaces and allow natural language use. Because question answering over knowledge bases (KBQAs) is a very active research topic, a comprehensive view of the field is essential. The purpose of this study was to conduct a systematic review of methods and systems for KBQAs to identify their main advantages and limitations. The inclusion criteria rationale was English full-text articles published since 2015 on methods and systems for KBQAs. Sixty-six articles were reviewed to describe their underlying reference architectures.	2022	https://doi.org/10.1049/sfw2.12028	Related Work	TRUE	IET Software	Review	The usual access to this data has been through visual navigation interfaces and commonly through SPARQL Protocol and RDF Query Language (SPARQL) endpoints, but these access methods have problems. The first approach is not rich enough to answer more complex questions, and the second is not suitable for users who have not mastered the use of formal querying languages. Therefore, this reality is pressing for new question answering over knowledge base (KBQA) solutions for biomedical data.	In this work, we followed a strict methodology. To enable repeatability, we have created a replication package that is available online. We have used PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to report the protocol's execution and present the findings.	We analysed 66 documents to classify KBQA systems according to their architectural styles. We reported 25 semantic parsing pipeline systems, 12 using subgraph matching, 7 based on templates, and 22 performing information extraction. We look at the challenges ahead and identify some directions for future research.		Freebase, DBpedia, Wikidata	QALD, WebQuestions, WebQuestionsSP, SimpleQuestions, BioASQ, LC-QuAD, Free917, 		Scopus, Web of Science, IEEE Xplore, ACM Digital Library	On the one hand, it is necessary to answer increasingly complex questions, and on the other hand, we need to deal with the natural incompleteness of KBs	https://osf.io/hxyvw		Only one paragraph targeting multilingualism
Jorão Gomes Jr., Rômulo Chrispim de Mello, Victor Ströele & Jairo Francisco de Souza	A study of approaches to answering complex questions over knowledge bases	Question answering (QA) systems retrieve the most relevant answer to a natural language question. Knowledge base question answering (KBQA) systems explore entities and relations from knowledge bases to generate answers. Currently, QA systems achieve better results when answering simple questions, but complex QA systems are receiving great attention nowadays. However, there is a lack of studies that analyzes complex questions inside the KBQA field and how it has been addressed. This work aims to fill this gap, presenting a systematic mapping on the complex knowledge base question answering (C-KBQA). The main contributions of this work are: (i) the use of a systematic method to provide an overview of C-KBQA; (ii) a collection of 54 papers systematically selected from 894 papers; (iii) the identification of the most frequent venues, domains, and knowledge bases used in the literature; (iv) a mapping of methods, datasets, and metrics used in the C-KBQA scenario; (v) future directions and the main gaps in the C-KBQA field. The authors show that the C-KBQA system aims to solve two question types: multi-hop and constraint questions. Also, it was possible to identify three main steps to construct a C-KBQA system and the use of two main approaches in this process. It was also noticed that datasets for C-KBQA are still an open challenge.	2022	https://link.springer.com/article/10.1007/s10115-022-01737-x	Related Work	FALSE	Knowledge and Information Systems	Review	There is a lack of studies that analyze complex natural language questions inside the KBQA field and how it has been addressed	Presenting a systematic mapping on the complex knowledge base question answering systems. Understanding the solutions for C-KBQA includes the investigation of techniques that are most used, the main current solutions, where these solutions are applied, and, therefore, the identification of the main challenges of this research field	A collection of 54 papers systematically selected from 898 papers; (iii) the identification of the most frequent venues, domains, and knowledge bases used in the literature; (iv) a mapping of methods, datasets, and metrics used in the complex question answering scenario; (v) future directions and the main gaps in the C-KBQA area. We show that the C-KBQA system tries to solve two types of complex questions: multi-hop questions and constraint questions. Also, we identified three main steps to construct C-KBQA systems and the use of two main approaches in this process. We also notice that datasets for C-KBQA are still an open challenge, and the most used datasets are composed of only a few kinds of complex questions. At last, we saw that the C-KBQA area is still rising and it is expected to see a new C-KBQA system or new modules trying to improve current C-KBQA systems over the next years.									
				https://arxiv.org/abs/2209.04994	Related Work	FALSE	Arxiv	Review												